{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GridSearchCVTest",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Klauszhao/GameCode/blob/master/GridSearchCVTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2bpfyEmCQFt",
        "colab_type": "text"
      },
      "source": [
        "### 网格搜索\n",
        "使用网格搜索法对5个模型进行调优（调参时采用五折交叉验证的方式），并进行模型评估，记得展示代码的运行结果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbHFjyhvCY8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import lightgbm as lgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import cross_val_score,cross_val_predict\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOHv5AhWLkty",
        "colab_type": "code",
        "outputId": "6624ce3b-2265-4bd4-92f1-33e53a8bcad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "# 连接 Google colab 的云盘，数据集存放在云盘中，如果你的数据集不在云盘中，这段代码可以注释掉，从自己本地读取数据集\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls 'gdrive/My Drive/Data'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "aspect-extract\tdataAnalyse  dataProcessByTwoTask.csv  zhaopin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qutpM3eGC7pW",
        "colab_type": "code",
        "outputId": "4217d12e-f16f-499f-8293-b0f66745a497",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# 读取数据\n",
        "filePath = 'gdrive/My Drive/Data/dataProcessByTwoTask.csv'\n",
        "data = pd.read_csv(filePath,encoding='gbk')\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size=0.3, random_state=2018)\n",
        "print(\"train_data\",train_data.shape)\n",
        "print(\"test_data\",test_data.shape)\n",
        "\n",
        "y_train = train_data['status']\n",
        "x_train = train_data.drop(['status'],axis =1)\n",
        "\n",
        "y_test = test_data['status']\n",
        "x_test = test_data.drop(['status'],axis =1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data (3096, 70)\n",
            "test_data (1327, 70)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA64KGAb8caJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_score_train = []   \n",
        "decision_score_train = [] \n",
        "model_score_test = []   \n",
        "decision_score_test = []\n",
        "\n",
        "def proc_score(y_pred,y_pred_scores,y_test,train=True):  \n",
        "    accuracy = accuracy_score(y_test,y_pred)\n",
        "    precision = precision_score(y_test,y_pred)\n",
        "    recall = recall_score(y_test,y_pred)\n",
        "    f1 = f1_score(y_test,y_pred)\n",
        "    roc_auc = roc_auc_score(y_test,y_pred_scores)\n",
        "\n",
        "    if train:\n",
        "        decision_score_train.append(y_pred_scores)\n",
        "        model_score_train.append([accuracy,precision,recall,f1,roc_auc])\n",
        "        text = 'Train'\n",
        "    else:\n",
        "        decision_score_test.append(y_pred_scores)\n",
        "        model_score_test.append([accuracy,precision,recall,f1,roc_auc])\n",
        "        text = 'Test'\n",
        "    #print('{} confusion matrix:\\n{}'.format(text,confusion_matrix(y_test,y_pred)))\n",
        "    print('{}: accuracy : {:.3f} , precision : {:.3f} , recall : {:.3f} , f1 : {:.3f} , roc_auc : {:.3f}'.format(text,accuracy,precision,recall,f1,roc_auc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UJNbesIDMZd",
        "colab_type": "text"
      },
      "source": [
        "### GridSearchCV 函数说明\n",
        "- cv_results_  :   用来输出cv结果的，可以是字典形式也可以是numpy形式，还可以转换成DataFrame格式\n",
        "- best_estimator_  ：通过搜索参数得到的最好的估计器，当参数refit=False时该对象不可用\n",
        "- best_score_  ：float类型，输出最好的成绩\n",
        "- best_params_  :  通过网格搜索得到的score最好对应的参数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK0rPQA1FOU3",
        "colab_type": "text"
      },
      "source": [
        "### 逻辑回归\n",
        " 使用逻辑回归运行五折交叉验证，网格搜索来获取最优参数，下面代码中C为正则化系数λ的倒数，必须为正数，默认为1，值越小，代表正则化越强。 一般来说需要调节这个参数，网格搜索只需要探讨这个参数为什么值可以取得较好的效果。\n",
        " \n",
        "penalty: l1 和 l2 ，默认 l2 。若选择 l1 正则化，参数 solver 仅能够使用求解方式 liblinear 和 saga ；若使用 l2 正则化，参数 solver 中所有的求解方式都可以使用。\n",
        "\n",
        "param_grid 中有多个C 值，网格搜索会得到具体的值"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN51ozrZKcvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LRGridSearch(x_train,y_train,x_test,y_test):\n",
        "\n",
        "  parameters = {'penalty':['l1','l2'],'C':np.linspace(0.05,1,20).tolist()}\n",
        "  \n",
        "  grid_lr = GridSearchCV(LogisticRegression(), param_grid=parameters, cv=5, scoring='roc_auc')\n",
        "  grid_lr.fit(x_train,y_train)\n",
        "  #print(\"The best parameters are %s with a score of %0.2f\"% (grid_lr.best_params_, grid_lr.best_score_))\n",
        "  print(\"Test set score:{:.2f}\".format(grid_lr.score(x_train,y_train)))\n",
        "  print(\"Best parameters:{},Best score on train set:{:.2f}\".format(grid_lr.best_params_,grid_lr.best_score_))\n",
        "  #print(\"Best score on train set:{:.2f}\".format(grid_lr.best_score_))\n",
        "  \n",
        "  \n",
        "  # test_set score\n",
        "  LR=grid_lr.best_estimator_\n",
        "  \n",
        "#  y_proba = LR.predict_proba(x_test)\n",
        "#  y_predi = LR.predict(x_test)\n",
        "#   d = np.vstack((y_proba.T[0].T, y_proba.T[1].T, y_predi, y_test.T)).T\n",
        "#   d = d[d[:,0].argsort()]\n",
        "#   Eva(d,LR.score(x_test, y_test))\n",
        "\n",
        "  y_pred = LR.predict(x_test)\n",
        "  y_pred_scores = cross_val_predict(LR,x_test,y_test,cv=5,method='decision_function')\n",
        "  proc_score(y_pred,y_pred_scores,y_test,train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NX-q74v14Ia",
        "colab_type": "text"
      },
      "source": [
        "### 决策树\n",
        "\n",
        "分类树的8个重要参数：criterion、2个随机性相关的参数 (random_state、splitter）、5个剪枝参数（max_depth、min_samples_split、min_samples_leaf、max_feature、min_impurity_decrease）。\n",
        "\n",
        "- criterion：不纯度计算方法。信息熵 entropy 和基尼系数 gini ，默认 gini。\n",
        "\n",
        "-random_state：设置分枝中随机模式的参数。默认为 None。\n",
        "\n",
        "- splitter：控制决策树中的随机选项。best 和random ，默认最佳分枝 best（分枝虽随机，但会优先选择更重要的特征分枝）。\n",
        "\n",
        "- max_depth：树大最大深度。建议从3开始尝试。\n",
        "\n",
        "- min_samples_split：一个节点至少包含 min_samples_split 个训练样本。默认为2。\n",
        "\n",
        "- min_samples_leaf：一个节点在分枝后的每个子节点都必须包含 min_samples_leaf 个训练样本。建议从5开始尝试。\n",
        "\n",
        "- max_features：限制分枝时考虑的特征个数（和 max_depth 异曲同工）。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK758bjo_kXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DecisionTreeGridSearch(x_train,y_train,x_test,y_test):\n",
        "  param_grid ={'splitter':('best','random'),\n",
        "              'criterion':('gini','entropy'),\n",
        "              'max_depth':[*range(1,10)],\n",
        "              'min_samples_leaf':[*range(1,50,5)],\n",
        "              'min_impurity_decrease':[*np.linspace(0,0.5,10)],\n",
        "              }\n",
        "  \n",
        "  \n",
        "#   {'max_depth':np.linspace(2,32,31,dtype=np.int32),\n",
        "#              'min_samples_split':np.linspace(0.1, 1.0, 10, endpoint=True),\n",
        "#              'min_samples_leaf':np.linspace(0.1, 0.5, 5, endpoint=True),\n",
        "#              'class_weight':['balanced']}\n",
        "\n",
        "  gs_clf = GridSearchCV(DecisionTreeClassifier(),param_grid=param_grid,iid=True,cv=5,verbose=2,n_jobs=-1,scoring='roc_auc')\n",
        "  gs_clf.fit(x_train,y_train)\n",
        "  \n",
        "  print('Test set score: {:.3f}'.format(gs_clf.score(x_test,y_test)))\n",
        "  print('Best parameters: {}'.format(gs_clf.best_params_))\n",
        "  print('Best cross-validation score: {:.3f}'.format(gs_clf.best_score_))\n",
        "  print('Best estimator:\\n{}'.format(gs_clf.best_estimator_))\n",
        "  \n",
        "  \n",
        "  dt_clf = gs_clf.best_estimator_\n",
        "  y_pred = dt_clf.predict(x_test)\n",
        "  y_pred_scores = cross_val_predict(dt_clf,x_test,y_test,cv=5,method='predict_proba')\n",
        "  proc_score(y_pred,y_pred_scores[:,1],y_test,train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrJVGccOHf9W",
        "colab_type": "text"
      },
      "source": [
        "# 随机森林\n",
        "\n",
        "控制基评估器的参数：criterion、max_depth、min_samples_split、min_samples_leaf、max_feature、min_impurity_decrease。\n",
        "\n",
        "- n_estimators:森林中树木的数量，即基评估器的数量。n_estimators越大，模型的效果越好。n_estimators的默认值在现有版本的sklearn中是10，但是在即将更新的0.22版本中，这个默认值会被修正为100。一般来说，0-200选一个数会比较好。\n",
        "\n",
        "- random_state:控制生成森林的模式。而在分类树最后，一个random_state只控制生成一棵树。\n",
        "\n",
        "- bootstrap：控制抽样技术的参数，默认为True，代表有放回的抽样技术。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL64pt5uHihL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def RandomForestGridSearch(x_train,y_train,x_test,y_test):\n",
        "\n",
        "#   parameters = {'max_depth': [3, 4, 5, 6, 7],\n",
        "#                 'max_features': sp_randint(1, 11),\n",
        "#                 'min_samples_split': sp_randint(2, 11),\n",
        "#                 'bootstrap': [True, False],\n",
        "#                 'criterion': ['gini', 'entropy']\n",
        "#                 }\n",
        "  # 简单的参数\n",
        "  parameters = {'max_depth':range(3,14,2), 'min_samples_split':range(50,201,20)}\n",
        "  n_iter_search = 20\n",
        "  \n",
        "  gs_clf = GridSearchCV(RandomForestClassifier(n_estimators=100,criterion='gini'), parameters,cv=5, iid=False, scoring='roc_auc')\n",
        "  gs_clf.fit(x_train, y_train)\n",
        "  \n",
        "  print('Test set score: {:.3f}'.format(gs_clf.score(x_test,y_test)))\n",
        "  print('Best parameters: {}'.format(gs_clf.best_params_))\n",
        "  print('Best cross-validation score: {:.3f}'.format(gs_clf.best_score_))\n",
        "  print('Best estimator:\\n{}'.format(gs_clf.best_estimator_))\n",
        "  \n",
        "  rfc =gs_clf.best_estimator_\n",
        " \n",
        "  y_pred = rfc.predict(x_test)\n",
        "  y_pred_scores = cross_val_predict(rfc,x_test,y_test,cv=5,method='predict_proba')\n",
        "  proc_score(y_pred,y_pred_scores[:,1],y_test,train=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1Nx0HCrL3xH",
        "colab_type": "text"
      },
      "source": [
        "### XGBoost\n",
        "- max_depth: 每棵树的最大深度。太小会欠拟合，太大过拟合。正常值是3到10。\n",
        "\n",
        "- learning_rate: 学习率，也就是梯度下降法中的步长。太小的话，训练速度太慢，而且容易陷入局部最优点。通常是0.0001到0.1之间。\n",
        "\n",
        "- n_estimators: 树的个数。并非越多越好，通常是50到1000之间。\n",
        "\n",
        "- colsample_bytree: 训练每个树时用的特征的数量。1表示使用全部特征，0.5表示使用一半的特征。\n",
        "\n",
        "- subsample: 训练每个树时用的样本的数量。与上述类似，1表示使用全部样本，0.5表示使用一半的样本。\n",
        "\n",
        "- reg_alpha: L1正则化的权重。用来防止过拟合。一般是0到1之间。\n",
        "\n",
        "- reg_lambda: L2正则化的权重。用来防止过拟合。一般是0到1之间。\n",
        "\n",
        "- min_child_weight: 每个子节点所需要的样本的数量（加权的数量）。若把它设置为大于1的数值，可以起到剪枝的效果，防止过拟合。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrehMKXWL2RK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def XGBGridSearch(x_train,y_train,x_test,y_test):\n",
        "  parameters = {'max_depth': [3, 4, 5, 6, 7, 8],\n",
        "                'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "                'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "                'learning_rate': [0.01, 0.1, 0.2],\n",
        "                'min_child_weight': [1, 2, 3],\n",
        "                }\n",
        "  # 简单的参数\n",
        "  parameters = {'max_depth':range(3,10,2), 'min_child_weight':range(1,6,1)}\n",
        "  \n",
        "  n_iter_search = 20\n",
        "  gs_clf = GridSearchCV(XGBClassifier(random_state=2018), parameters, cv=5, iid=False, scoring='roc_auc')\n",
        "  gs_clf.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "  print('Test set score: {:.3f}'.format(gs_clf.score(x_test,y_test)))\n",
        "  print('Best parameters: {}'.format(gs_clf.best_params_))\n",
        "  print('Best cross-validation score: {:.3f}'.format(gs_clf.best_score_))\n",
        "  print('Best estimator:\\n{}'.format(gs_clf.best_estimator_))\n",
        "  \n",
        "  xgbst = gs_clf.best_estimator_\n",
        "  y_pred = xgbst.predict(x_test)\n",
        "  y_pred_scores = cross_val_predict(xgbst,x_test,y_test,cv=5,method='predict_proba')\n",
        "  proc_score(y_pred,y_pred_scores[:,1],y_test,train=False)\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA-Qlno8N9Hz",
        "colab_type": "text"
      },
      "source": [
        "### GBDT \n",
        "\n",
        "参数 训练，参数很多，训练很慢，可以分多次训练，多个参数分开网格搜索，但是这样得到的结果可能不太一样，\n",
        "不过我觉得跟训练集关系很大，不同的训练集，训练的参数不太一样。\n",
        "\n",
        "本文训练的最佳的参数如下\n",
        "\n",
        "```\n",
        "\n",
        "criterion='friedman_mse', init=None,\n",
        "                           learning_rate=0.2, loss='deviance', max_depth=5,\n",
        "                           max_features='sqrt', max_leaf_nodes=None,\n",
        "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "                           min_samples_leaf=80, min_samples_split=1400,\n",
        "                           min_weight_fraction_leaf=0.0, n_estimators=60,\n",
        "                           n_iter_no_change=None, presort='auto',\n",
        "                           random_state=10, subsample=0.8, tol=0.0001,\n",
        "                           validation_fraction=0.1, verbose=0,\n",
        "                           warm_start=False\n",
        "\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrlTqaOfOZJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GBDTGridSearch(x_train,y_train,x_test,y_test):\n",
        "  \n",
        "  parameters = {'n_estimators':range(20,81,10)\n",
        "                ,'learning_rate':[0.05,0.1,0.2,0.5]\n",
        "                ,'max_depth':range(3,14,2)\n",
        "              }\n",
        "  #  暂时放弃这下面两个参数的训练\n",
        "  #  ,'min_samples_split':range(800,1900,200)\n",
        "  #  ,'min_samples_leaf':range(60,101,10)\n",
        "  \n",
        "  gs_clf = GridSearchCV(estimator = GradientBoostingClassifier( min_samples_leaf=80, min_samples_split=1400,max_features='sqrt', subsample=0.8, random_state=10), \n",
        "                         param_grid = parameters, scoring='roc_auc',iid=False, cv=5)\n",
        "  \n",
        "  gs_clf.fit(x_train,y_train)\n",
        "  \n",
        "  print('Test set score: {:.3f}'.format(gs_clf.score(x_test,y_test)))\n",
        "  print('Best parameters: {}'.format(gs_clf.best_params_))\n",
        "  print('Best cross-validation score: {:.3f}'.format(gs_clf.best_score_))\n",
        "  print('Best estimator:\\n{}'.format(gs_clf.best_estimator_))\n",
        "  \n",
        "  gbdt = gs_clf.best_estimator_\n",
        "  y_pred = gbdt.predict(x_test)\n",
        "  y_pred_scores = cross_val_predict(gbdt,x_test,y_test,cv=5,method='predict_proba')\n",
        "  proc_score(y_pred,y_pred_scores[:,1],y_test,train=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mo8GN62u123",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4e1c1efb-b6a5-4b71-e40b-9f1a752f3cab"
      },
      "source": [
        "print(\"- - - - - - - - - - - - - - - - - - - 原始测试集，开始训练 - - - - - - - - - - - - - - - - - - - - - \")\n",
        "print(\"- - - -  - - LR - - - - - - - - \")\n",
        "LRGridSearch(x_train,y_train,x_test,y_test)\n",
        "print(\"- - - -  - - 决策树 - - - - - - - - \")\n",
        "DecisionTreeGridSearch(x_train,y_train,x_test,y_test)\n",
        "print(\"- - - -  - - 随机森林 - - - - - - - - \")\n",
        "\n",
        "RandomForestGridSearch(x_train,y_train,x_test,y_test)\n",
        "\n",
        "print(\"- - - -  - - XGB - - - - - - - - \")\n",
        "\n",
        "XGBGridSearch(x_train,y_train,x_test,y_test)\n",
        "\n",
        "print(\"- - - -  - - GBDT - - - - - - - - \")\n",
        "GBDTGridSearch(x_train,y_train,x_test,y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- - - - - - - - - - - - - - - - - - - 原始测试集，开始训练 - - - - - - - - - - - - - - - - - - - - - \n",
            "- - - -  - - LR - - - - - - - - \n",
            "Test set score:0.82\n",
            "Best parameters:{'C': 0.25, 'penalty': 'l1'},Best score on train set:0.80\n",
            "Test: accuracy : 0.775 , precision : 0.647 , recall : 0.321 , f1 : 0.429 , roc_auc : 0.744\n",
            "- - - -  - - 决策树 - - - - - - - - \n",
            "Fitting 5 folds for each of 3600 candidates, totalling 18000 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 195 tasks      | elapsed:    4.0s\n",
            "[Parallel(n_jobs=-1)]: Done 1647 tasks      | elapsed:   17.5s\n",
            "[Parallel(n_jobs=-1)]: Done 4083 tasks      | elapsed:   42.5s\n",
            "[Parallel(n_jobs=-1)]: Done 7479 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done 11859 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done 17199 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=-1)]: Done 18000 out of 18000 | elapsed:  3.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set score: 0.707\n",
            "Best parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 36, 'splitter': 'best'}\n",
            "Best cross-validation score: 0.751\n",
            "Best estimator:\n",
            "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=5,\n",
            "                       max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=36, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort=False,\n",
            "                       random_state=None, splitter='best')\n",
            "Test: accuracy : 0.756 , precision : 0.557 , recall : 0.350 , f1 : 0.430 , roc_auc : 0.715\n",
            "- - - -  - - 随机森林 - - - - - - - - \n",
            "Test set score: 0.775\n",
            "Best parameters: {'max_depth': 5, 'min_samples_split': 70}\n",
            "Best cross-validation score: 0.793\n",
            "Best estimator:\n",
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=70,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "Test: accuracy : 0.765 , precision : 0.718 , recall : 0.175 , f1 : 0.281 , roc_auc : 0.764\n",
            "- - - -  - - XGB - - - - - - - - \n",
            "Test set score: 0.792\n",
            "Best parameters: {'max_depth': 3, 'min_child_weight': 5}\n",
            "Best cross-validation score: 0.795\n",
            "Best estimator:\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=5, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=2018,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n",
            "Test: accuracy : 0.782 , precision : 0.672 , recall : 0.335 , f1 : 0.447 , roc_auc : 0.762\n",
            "- - - -  - - GBDT - - - - - - - - \n",
            "Test set score: 0.780\n",
            "Best parameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 60}\n",
            "Best cross-validation score: 0.805\n",
            "Best estimator:\n",
            "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.2, loss='deviance', max_depth=5,\n",
            "                           max_features='sqrt', max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=80, min_samples_split=1400,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=60,\n",
            "                           n_iter_no_change=None, presort='auto',\n",
            "                           random_state=10, subsample=0.8, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "Test: accuracy : 0.787 , precision : 0.681 , recall : 0.361 , f1 : 0.472 , roc_auc : 0.500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCEd9qKMvsSQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1716c372-f5ea-4b7e-e651-7455a0b3a204"
      },
      "source": [
        "# 数据归一化操作\n",
        "\n",
        "print(\"- - - - - - - - - - - - - - - - - - - 归一化测试集，开始训练 - - - - - - - - - - - - - - - - - - - - - \")\n",
        "\n",
        "x_train_scale =minmax_scale(x_train)\n",
        "x_test_scale =minmax_scale(x_test)\n",
        "\n",
        "print(\"- - - -- - - - - -   - - LR - - - - - - - - - - -  - - - \")\n",
        "LRGridSearch(x_train_scale,y_train,x_test_scale,y_test)\n",
        "print(\"- - - -  - - 决策树 - - - - - - - - \")\n",
        "DecisionTreeGridSearch(x_train_scale,y_train,x_test_scale,y_test)\n",
        "print(\"- - - - - - - - - -  - - 随机森林 - -- - - - - -  - - - - - - \")\n",
        "\n",
        "RandomForestGridSearch(x_train_scale,y_train,x_test_scale,y_test)\n",
        "\n",
        "print(\"- - - - - - - - - -  - - XGB - - - - - -- - - - - -  - - \")\n",
        "\n",
        "XGBGridSearch(x_train_scale,y_train,x_test_scale,y_test)\n",
        "\n",
        "print(\"- - - - - - - - - -  - - GBDT - - - - - -- - - - - -  - - \")\n",
        "GBDTGridSearch(x_train_scale,y_train,x_test_scale,y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- - - - - - - - - - - - - - - - - - - 归一化测试集，开始训练 - - - - - - - - - - - - - - - - - - - - - \n",
            "- - - -- - - - - -   - - LR - - - - - - - - - - -  - - - \n",
            "Test set score:0.81\n",
            "Best parameters:{'C': 1.0, 'penalty': 'l1'},Best score on train set:0.80\n",
            "Test: accuracy : 0.770 , precision : 0.589 , recall : 0.415 , f1 : 0.487 , roc_auc : 0.759\n",
            "- - - -  - - 决策树 - - - - - - - - \n",
            "Fitting 5 folds for each of 3600 candidates, totalling 18000 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 296 tasks      | elapsed:    4.7s\n",
            "[Parallel(n_jobs=-1)]: Done 2474 tasks      | elapsed:   25.2s\n",
            "[Parallel(n_jobs=-1)]: Done 6128 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done 11222 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=-1)]: Done 17792 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=-1)]: Done 18000 out of 18000 | elapsed:  3.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set score: 0.724\n",
            "Best parameters: {'criterion': 'gini', 'max_depth': 9, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 41, 'splitter': 'random'}\n",
            "Best cross-validation score: 0.752\n",
            "Best estimator:\n",
            "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
            "                       max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=41, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort=False,\n",
            "                       random_state=None, splitter='random')\n",
            "Test: accuracy : 0.736 , precision : 0.499 , recall : 0.513 , f1 : 0.506 , roc_auc : 0.702\n",
            "- - - - - - - - - -  - - 随机森林 - -- - - - - -  - - - - - - \n",
            "Test set score: 0.783\n",
            "Best parameters: {'max_depth': 7, 'min_samples_split': 50}\n",
            "Best cross-validation score: 0.793\n",
            "Best estimator:\n",
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "                       max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=50,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "Test: accuracy : 0.775 , precision : 0.722 , recall : 0.238 , f1 : 0.358 , roc_auc : 0.764\n",
            "- - - - - - - - - -  - - XGB - - - - - -- - - - - -  - - \n",
            "Test set score: 0.782\n",
            "Best parameters: {'max_depth': 3, 'min_child_weight': 3}\n",
            "Best cross-validation score: 0.795\n",
            "Best estimator:\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=3, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=2018,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n",
            "Test: accuracy : 0.769 , precision : 0.603 , recall : 0.352 , f1 : 0.445 , roc_auc : 0.762\n",
            "- - - - - - - - - -  - - GBDT - - - - - -- - - - - -  - - \n",
            "Test set score: 0.782\n",
            "Best parameters: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 60}\n",
            "Best cross-validation score: 0.805\n",
            "Best estimator:\n",
            "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.2, loss='deviance', max_depth=5,\n",
            "                           max_features='sqrt', max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=80, min_samples_split=1400,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=60,\n",
            "                           n_iter_no_change=None, presort='auto',\n",
            "                           random_state=10, subsample=0.8, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n",
            "Test: accuracy : 0.766 , precision : 0.567 , recall : 0.470 , f1 : 0.514 , roc_auc : 0.500\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}